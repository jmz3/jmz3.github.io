<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Guide on 张嘉铭</title>
    <link>https://zhang-jiaming.com/pt-cn/categories/guide/</link>
    <description>Recent content in Guide on 张嘉铭</description>
    <generator>Hugo</generator>
    <language>zh</language>
    <lastBuildDate>Mon, 01 Sep 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://zhang-jiaming.com/pt-cn/categories/guide/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>OpenIRIS: Eye Tracking Software for Vestibular and Oculomotor Research</title>
      <link>https://zhang-jiaming.com/pt-cn/posts/openiris/</link>
      <pubDate>Mon, 01 Sep 2025 00:00:00 +0000</pubDate>
      <guid>https://zhang-jiaming.com/pt-cn/posts/openiris/</guid>
      <description>&lt;p&gt;I contributed to the development of &lt;a href=&#34;https://github.com/jmz3/OpenIris&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;OpenIRIS&lt;/a&gt;. OpenIris is an adaptable, open-source framework for video-based eye-tracking, developed in C# with a modular design for plugin extension. It supports online and offline recording, binocular pupil tracking, and 3-D eye motion capture.&lt;/p&gt;&#xA;&lt;p&gt;To be more specific, I added support for USB version of Flir Blackfly cameras, and implemented a online calibration module to calculate the head pose from gravitational vector recorded by an IMU.&lt;/p&gt;</description>
    </item>
    <item>
      <title>ROS Driver for Fantronic Endoscopic Camera</title>
      <link>https://zhang-jiaming.com/pt-cn/posts/endoscope/</link>
      <pubDate>Sat, 01 Feb 2025 00:00:00 +0000</pubDate>
      <guid>https://zhang-jiaming.com/pt-cn/posts/endoscope/</guid>
      <description>&lt;p&gt;ROS1 image acquisition node for Fantronic/Geek Szitman endoscope camera. Supports USB connection. The camera can be purchased from Amazon from this &lt;a href=&#34;https://www.amazon.com/Inspection-Fantronics-Waterproof-Borescope-Adjustable/dp/B071HYRPND/ref=sr_1_1?dib=eyJ2IjoiMSJ9.zV1nqWnHEaSPdDiEHPP-RR0QeNAKRdKZrFqpH4skcsN3PcgYNpxxTd6n7FiPC8P5tZGjM3trSpj6Kf3AFw_GKZEuedP192EytwbsxPGmPA1LpuSVsZsCBGXyOL7zAXDaDGNGVcRh8U20rhtUt3EaU_U28Zv6Vmek0d28AWBRLqsjTfgybdPsb2lMmwTV2snLAotug0pMbluLOvZuIaJqgaEi97xg6jiTay9z4I9uhnA.GCo8pb43OOxapIJryI-bXsVdCcCdcgvRvehpc-ynycg&amp;amp;dib_tag=se&amp;amp;hvadid=651109964328&amp;amp;hvdev=c&amp;amp;hvexpln=0&amp;amp;hvlocphy=9007900&amp;amp;hvnetw=g&amp;amp;hvocijid=14768633232462871144--&amp;amp;hvqmt=e&amp;amp;hvrand=14768633232462871144&amp;amp;hvtargid=kwd-262769191435&amp;amp;hydadcr=977_1015116299&amp;amp;keywords=fantronics&amp;#43;endoscope&amp;amp;mcid=47abe76b718d31c78381e745b67076b3&amp;amp;qid=1763698904&amp;amp;sr=8-1&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;link&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;With this ROS driver, you can easily use the endoscopic camera as wrist camera for da Vinci robot, who does not have native wrist camera support.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Robotic Transcranial Magnetic Stimulation</title>
      <link>https://zhang-jiaming.com/pt-cn/posts/rotms/</link>
      <pubDate>Wed, 01 Jan 2025 00:00:00 +0000</pubDate>
      <guid>https://zhang-jiaming.com/pt-cn/posts/rotms/</guid>
      <description>&lt;p&gt;With our advanced robotic system, surgeons can easily and accurately deliver non-invasive stimulations to the cortical area of the brain. The system is designed to be easy to use and can be operated by a single person. The system is currently being tested in a clinical trial at the Johns Hopkins Hospital.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Robust Realtime Shape Estimation of Deformable Linear Object</title>
      <link>https://zhang-jiaming.com/pt-cn/posts/deform/</link>
      <pubDate>Mon, 13 May 2024 00:00:00 +0000</pubDate>
      <guid>https://zhang-jiaming.com/pt-cn/posts/deform/</guid>
      <description>&lt;h2 id=&#34;deformable-object-simulation&#34;&gt;&#xA;  Deformable Object Simulation&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#deformable-object-simulation&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://zhang-jiaming.com/images/ICRADemo2024.gif&#34; alt=&#34;Deformable Object Simulation&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;The existing methods of shape estimation of continuum objects create dense point clouds from camera images, and/or use distinguishable markers on a deformable body. They have natural limitations in realtime tracking of large continuum objects/manipulators and the physical occlusion of markers can often compromise accurate shape estimation. We propose a robust method to estimate the shape of linear deformable objects in realtime using scattered and unordered key points. By utilizing a robust probability-based labeling algorithm, our approach identifies the true order of the detected key points and then reconstructs the shape using piecewise spline interpolation. The proposed method is implemented in C++ and integrated with ROS. The code is available &lt;a href=&#34;https://github.com/jmz3/DeformableEstimation&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>SAMME: Segment Any Medical Model Extended</title>
      <link>https://zhang-jiaming.com/pt-cn/posts/sam/</link>
      <pubDate>Mon, 19 Feb 2024 00:00:00 +0000</pubDate>
      <guid>https://zhang-jiaming.com/pt-cn/posts/sam/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://zhang-jiaming.com/images/samme.png&#34; alt=&#34;SAMM overview&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;I&amp;rsquo;m excited to announce that our project &lt;a href=&#34;https://github.com/bingogome/samm&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;SAMM&lt;/a&gt; has received many attentions from all over the world! Please reach out if you want to collaborate. SAMM allows users to directly leverage the powerful Segment Anything Model (SAM) to segment medical images (including CT, MR, Ultrasound, and more) in 3D Slicer.&lt;/p&gt;</description>
    </item>
    <item>
      <title>PoseHub: Surgical Tool Tracking with AR Headset</title>
      <link>https://zhang-jiaming.com/pt-cn/posts/ar-track/</link>
      <pubDate>Thu, 01 Feb 2024 00:00:00 +0000</pubDate>
      <guid>https://zhang-jiaming.com/pt-cn/posts/ar-track/</guid>
      <description>&lt;h2 id=&#34;posehub-surgical-tool-tracking-with-ar-headset&#34;&gt;&#xA;  PoseHub: Surgical Tool Tracking with AR Headset&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#posehub-surgical-tool-tracking-with-ar-headset&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;We are developing a surgical tool tracking system that can be used with augmented reality headsets. The system is designed to provide real-time feedback to the surgeon about the location of the surgical tool. The system has a scene-graph structure that allows for easy integration with different tracking devices and visualization tools. A synthetic dataset is generated in ROS to test the system. The code is available &lt;a href=&#34;https://github.com/jmz3/PoseHub.git&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>XREGI: Learning-based 2D/3D Fluoroscopic Image Registration</title>
      <link>https://zhang-jiaming.com/pt-cn/posts/xregi/</link>
      <pubDate>Thu, 06 Apr 2023 00:00:00 +0000</pubDate>
      <guid>https://zhang-jiaming.com/pt-cn/posts/xregi/</guid>
      <description>&lt;h2 id=&#34;learning-based-2d3d-fluoroscopic-image-registration&#34;&gt;&#xA;  Learning-based 2D/3D Fluoroscopic Image Registration&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#learning-based-2d3d-fluoroscopic-image-registration&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;We developed and maintained an open-source python package &lt;a href=&#34;https://github.com/jeremyzz830/xregi/tree/master&#34;  class=&#34;external-link&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;xregi&lt;/a&gt; that is used to compute the projection matrix between 2D x-ray images and 3D CT scans. This process is also called as 2D/3D fluoroscopic image registration problem. The package is now available on Pypi. Install the pacakge through &lt;code&gt;pip install xregi&lt;/code&gt; to try out!&lt;/p&gt;</description>
    </item>
    <item>
      <title>Install Nvidia Driver on Ubuntu 20.04</title>
      <link>https://zhang-jiaming.com/pt-cn/posts/install-nvidia-driver-on-ubuntu-20.04/</link>
      <pubDate>Wed, 01 Feb 2023 00:00:00 +0000</pubDate>
      <guid>https://zhang-jiaming.com/pt-cn/posts/install-nvidia-driver-on-ubuntu-20.04/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;&lt;strong&gt;Environment&lt;/strong&gt;&#xA;&lt;br&gt;&#xA;&lt;u&gt;Hardware&lt;/u&gt;: Lenovo y9000p 2019 - intel i7-9750H&lt;br&gt;&#xA;&lt;u&gt;OS&lt;/u&gt;: Ubuntu 20.04 LTS Dual Boot&lt;br&gt;&#xA;&lt;u&gt;Kernel version&lt;/u&gt;: Linux 5.13.0-39-generic&lt;br&gt;&#xA;&lt;u&gt;GPU model&lt;/u&gt;: GTX 1660 Ti 6GB&lt;br&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;h1 id=&#34;install-nvidia-drivers-through-gui&#34;&gt;&#xA;  Install Nvidia Drivers through GUI&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#install-nvidia-drivers-through-gui&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://zhang-jiaming.com/static/images/test.png&#34; alt=&#34;test img&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;choose the right tested driver version via Software &amp;amp; Updates - Additional Drivers; then click apply changes&lt;/p&gt;&#xA;&lt;p&gt;wait for it to download and configure the drivers.&lt;/p&gt;&#xA;&lt;p&gt;After that, a window will prompt out to tell you you need to set up a key for secure boot. Type in whatever you want, just try to record/remember what you just type.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Configurations about Hugo-Coder Theme</title>
      <link>https://zhang-jiaming.com/pt-cn/posts/configurations/</link>
      <pubDate>Tue, 10 Jan 2023 00:00:00 +0000</pubDate>
      <guid>https://zhang-jiaming.com/pt-cn/posts/configurations/</guid>
      <description>&lt;h1 id=&#34;configurations&#34;&gt;&#xA;  Configurations&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#configurations&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#about-hugo-configurations&#34; &gt;About Hugo Configurations&lt;/a&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#analytics&#34; &gt;Analytics&lt;/a&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#google-analytics&#34; &gt;Google Analytics&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#google-tag-manager&#34; &gt;Google Tag Manager&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#fathom-analytics&#34; &gt;Fathom Analytics&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#plausible-analytics&#34; &gt;Plausible Analytics&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#goat-counter&#34; &gt;Goat Counter&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#cloudflare&#34; &gt;Cloudflare&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#matomo&#34; &gt;Matomo&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#application-insights&#34; &gt;Application Insights&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#commenting-systems&#34; &gt;Commenting Systems&lt;/a&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#disqus&#34; &gt;Disqus&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#commento&#34; &gt;Commento&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#utterances&#34; &gt;Utterances&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#giscus&#34; &gt;Giscus&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#theme-parameters&#34; &gt;Theme Parameters&lt;/a&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#social-icons-configuration&#34; &gt;Social Icons Configuration&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#menu-items-configurations&#34; &gt;Menu Items Configurations&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#csp&#34; &gt;CSP&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#complete-example&#34; &gt;Complete Example&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#front-matter&#34; &gt;Front Matter&lt;/a&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;#posts&#34; &gt;Posts&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;about-hugo-configurations&#34;&gt;&#xA;  About Hugo Configurations&#xA;  &lt;a class=&#34;heading-link&#34; href=&#34;#about-hugo-configurations&#34;&gt;&#xA;    &lt;i class=&#34;fa-solid fa-link&#34; aria-hidden=&#34;true&#34; title=&#34;Link to heading&#34;&gt;&lt;/i&gt;&#xA;    &lt;span class=&#34;sr-only&#34;&gt;Link to heading&lt;/span&gt;&#xA;  &lt;/a&gt;&#xA;&lt;/h2&gt;&#xA;&lt;p&gt;This theme supports:&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
